LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
Exterior1st, Exterior2nd, HeatingQC, BsmtFinType1, BsmtFinSF1, MSZoning, MasVnrArea, MasVnrType,
HouseStyle, OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
library(tree)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, KitchenQual, TotalBsmtSF, BsmtQual, MSSubClass, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, TotalBsmtSF, MSSubClass, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = lazy(SalePrice~., train)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, Neighborhood, Alley, GrLivArea,
GarageCars, GarageArea, YearBuilt, ExterQual, KitchenQual, TotalBsmtSF, BsmtQual, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, GarageFinish, FireplaceQu, YearRemodAdd, Foundation, Fence,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, MiscFeature, Fireplaces, LotArea, OpenPorchSF,
Exterior1st, Exterior2nd, HeatingQC, BsmtFinType1, BsmtFinSF1, MSZoning, MasVnrArea, MasVnrType,
HouseStyle, OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, FireplaceQu, YearRemodAdd, Foundation, Fence,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, MiscFeature, Fireplaces, LotArea, OpenPorchSF,
Exterior1st, Exterior2nd, HeatingQC, BsmtFinType1, BsmtFinSF1, MSZoning, MasVnrArea, MasVnrType,
HouseStyle, OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, YearRemodAdd,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1, MasVnrArea,
HouseStyle, OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, YearRemodAdd,
LotFrontage, TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1, MasVnrArea,
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = lazy(SalePrice~., train)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, YearRemodAdd,
TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1, MasVnrArea,
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = lazy(SalePrice~., train)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
library(tree)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, Neighborhood, Alley, GrLivArea,
GarageCars, GarageArea, YearBuilt, ExterQual, KitchenQual, TotalBsmtSF, BsmtQual, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, GarageFinish, FireplaceQu, YearRemodAdd, Foundation, Fence,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, MiscFeature, Fireplaces, LotArea, OpenPorchSF,
Exterior1st, Exterior2nd, HeatingQC, BsmtFinType1, BsmtFinSF1, MSZoning, MasVnrArea, MasVnrType,
HouseStyle, OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
tree.control(nobs=10, mincut = 1, minsize = 20, mindev = 10)
regtree = tree(SalePrice~., train)
plot(regtree)
text(regtree, pretty=0)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
library(tree)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, Neighborhood, Alley, GrLivArea,
GarageCars, GarageArea, YearBuilt, ExterQual, KitchenQual, TotalBsmtSF, BsmtQual, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, GarageFinish, FireplaceQu, YearRemodAdd, Foundation,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
Exterior1st, Exterior2nd, HeatingQC, BsmtFinType1, BsmtFinSF1, MSZoning, MasVnrArea, MasVnrType,
HouseStyle, OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = tree(SalePrice~., train)
plot(regtree)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, YearRemodAdd,
TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1, LotFrontage
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, YearRemodAdd,
TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1, LotFrontage,
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
View(train)
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, YearRemodAdd,
TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1, GarageYrBlt,
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
result[,"GarageYrBlt"] = rapply(result[,"GarageYrBlt"], f=function(x) ifelse(is.nan(x),0,x), how="replace")
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, YearRemodAdd,
TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1,
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
library(lazy)
#Filters the train dataframe
#Only higher than 0.1 IG features were selected
#Non-numeric and sparse features are however excluded since in is uneffective
#LotFrontage and GarageYrBlt and MasVnrArea excluded because of NaN values
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, YearRemodAdd,
TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1,
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
con=lazy.control(conIdPar=NULL, linIdPar=1, quaIdPar=NULL,
distance=c("manhattan","euclidean"), metric=NULL,
cmbPar=1, lambda=1e+03)
model = lazy(SalePrice~., train,control=con)
prediction = train[,1:(ncol(train)-1)]
prediction[,"PredictedPrice"] = predict(model, prediction)
prediction[,"RealPrice"] = train[,"SalePrice"]
rmse = sqrt(mean(prediction[,"PredictedPrice"] - prediction[,"RealPrice"])^2)
print(rmse)
View(prediction)
framesize = 300
while (nrow(train) > 0)
{
train = train[(framesize+1):nrow(train),]
}
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, YearRemodAdd,
TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1,
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
framesize = 300
x=1
while (nrow(train) > 0)
{
newf <- train[x:(x+framesize)]
x = x + framesize
}
framesize = 300
x=1
while (nrow(train) > 0)
{
newf <- train[x:(x+framesize)];
x = x + framesize;
}
framesize = 300
x=1
while (nrow(train) > 0)
{
newf <- train[x:(x+framesize),];
x = x + framesize;
}
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, YearRemodAdd,
TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1,
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
framesize = 300
x=1
newf=0
while (nrow(train) > 0)
{
newf <- train[x:(x+framesize),];
x = x + framesize;
}
framesize = 300
x=1
newf=0
while (x < nrow(train))
{
newf <- train[x:(x+framesize),];
x = x + framesize;
}
a = list("a", "b")
a = a + "c"
a = list(a, "c")
a = list("a", "b")
a = c(a, "c")
a = list("a", "b")
a = c(a, "c")
newf=list()
framesize = 300
x=1
newf=0
part
framesize = 300
x=1
newf=0
part=list()
while (x < nrow(train))
{
newf <- train[x:(x+framesize-1),];
part = c(part, newf)
x = x + framesize;
}
print(part)
framesize = 300
x=1
newf=0
part=list()
newf <- train[x:(x+framesize-1),];
View(newf)
data=[,,]
data=data.frame(2,3,4)
View(data)
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, YearRemodAdd,
TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1,
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
framesize = 300
x=1
newf=0
part=list()
newf <- train[x:(x+framesize-1),];
View(newf)
part = c(part, newf)
x = x + framesize;
part[1]
library(lazy)
library(tree)
library(e1071)
library(stats)
setwd('D:/kaggle')  #TO-MODIFY sets the defaul folder depending on the directory path!!!
source("parameters.R")
source("split-folds.R")
source("feature-filter.R")
evaluate <- function(prediction)
{
return(mean((prediction[,"PredictedPrice"] - prediction[,"RealPrice"])^2))
}
cross_validation <- function(folds, model_flag, param)
{
mse_all = c()
iteration = 1
while (iteration <= length(folds))
{
test = folds[[iteration]]
train = data.frame()
fold_num = 1
while (fold_num <= length(folds))
{
if (fold_num != iteration)
train <- rbind(train, folds[[fold_num]])
fold_num = fold_num + 1
}
model = teach_model(train, model_flag, param)
prediction = test[,1:(ncol(test)-1)]
predicted = predict(model, prediction)
mse = mean((predicted[[1]] - test[,"SalePrice"])^2)
mse_all = c(mse_all, mse)
iteration = iteration + 1
}
return(sqrt(mse))
}
teach_model <- function(train, model_flag, param)
{
if (model_flag == 1)
{
model = tree(SalePrice~., train, control = tree.control(nobs = param[1, 'nobs'], mincut = param[1, 'mincut'], minsize = param[1, 'minsize'], mindev = param[1, 'mindev']))
}
else if (model_flag == 2)
{
model = lazy(SalePrice~., train, control = lazy.control(conIdPar=NULL, linIdPar=param[1, 'linIdPar'], quaIdPar=NULL, distance=c("manhattan","euclidean"), metric=NULL, cmbPar=1, lambda=param[1, 'lambda']))
}
else if (model_flag == 3)
{
model = svm(SalePrice~., train, degree=param[1, 'degree'], nu=param[1, 'nu'], cachesize = 100, tolerance=param[1, 'tolerance'], epsilon=param[1, 'epsilon'])
}
return(model)
}
select_model <- function(train, model_flag, param)
{
folds = split_folds(train)
rmse_all = c()
for (i in 1:nrow(param))
{
rmse = cross_validation(folds, model_flag, param[i, ])
rmse_all = c(rmse_all, rmse)
}
min_index = which.min(rmse_all)
min_value = min(rmse_all)
return(c(min_index, min_value))
}
train_raw = read.csv("./train.csv", header = TRUE)   #stringsAsFactors is necessary to remove NAs
train = feature_filter(train_raw)
train = reassign_factors(train, train)
train = replace_na(train)
lazy_parameters = get_lazy_parameters()
View(lazy_parameters)
result_lazy = select_model(train, 2, lazy_parameters)
model = lazy(SalePrice~., train,control=con)   #lazy
con=lazy.control(conIdPar=NULL, linIdPar=1, quaIdPar=NULL, distance=c("manhattan","euclidean"), metric=NULL, cmbPar=1, lambda=1e+03)
model = lazy(SalePrice~., train,control=con)   #lazy
prediction = train[,1:(ncol(train)-1)]
prediction[,"PredictedPrice"] = predict(model, prediction)
prediction[,"RealPrice"] = train[,"SalePrice"]
vec = prediction[,"PredictedPrice"] - prediction[,"RealPrice"]
mse = mean((prediction[,"PredictedPrice"] - prediction[,"RealPrice"])^2)
rmse = sqrt(mse)
print(rmse)
lazy_parameters = get_lazy_parameters()
source("parameters.R")
lazy_parameters = get_lazy_parameters()
result_lazy = select_model(train, 2, lazy_parameters)
print('lazy_index = ')
print(result_lazy[1])
print('lazy_rmse = ')
print(result_lazy[2])
tree_parameters = get_tree_parameters()
result_tree = select_model(train, 1, tree_parameters)
print('tree_index = ')
print(result_tree[1])
print('tree_rmse = ')
print(result_tree[2])
svm_parameters = get_svm_parameters()
result_svm = select_model(train, 3, svm_parameters)
print('svm_index = ')
print(result_svm[1])
print('svm_rmse = ')
print(result_svm[2])
tree_parameters = get_tree_parameters()[tree_conf_id,]
library(lazy)
library(tree)
library(e1071)
setwd('D:/kaggle')  #TO-MODIFY sets the defaul folder depending on the directory path!!!
source("parameters.R")
source("feature-filter.R")
train_raw = read.csv("./train.csv", header = TRUE)   #stringsAsFactors is necessary to remove NAs
train = feature_filter(train_raw)
train = reassign_factors(train, train)
train = replace_na(train)
tree_conf_id = 325
lazy_conf_id = 4
svm_conf_id = 81
tree_parameters = get_tree_parameters()[tree_conf_id,]
lazy_parameters = get_lazy_parameters()[lazy_conf_id,]
svm_parameters = get_svm_parameters()[svm_conf_id,]
rmse_tree = 84761
rmse_lazy = 27741
rmse_svm = 91465
p1 = 1 / rmse_tree
p2 = 1/ rmse_lazy
p3 = 1/ rmse_svm
s = p1 + p2 + p3
w1 = p1 / s
w2 = p2 / s
w3 = p3 / s
tree_model = teach_model(train, 1, tree_parameters)
lazy_model = teach_model(train, 2, lazy_parameters)
svm_model = teach_model(train, 3, svm_parameters)
prediction = train[,1:(ncol(train)-1)]
predicted_tree = predict(tree_model, prediction)
prediction = train[,1:(ncol(train)-1)]
predicted_lazy = predict(lazy_model, prediction)[[1]]  #[[1]] since lazy package implementation returns the result as a list containing a vector as the first element
prediction = train[,1:(ncol(train)-1)]
predicted_svm = predict(svm_model, prediction)
predicted = predicted_tree * w1 + predicted_lazy * w2 + predicted_svm * w3
mse = mean((predicted - train[,'SalePrice'])^2)
rmse = sqrt(mse)
test_raw = read.csv("./test.csv", header = TRUE)
test_raw = read.csv("./test.csv", header = TRUE)
test = feature_filter_without_saleprice(test_raw)
test = reassign_factors(train, test)
test_raw = read.csv("./test.csv", header = TRUE)
test = feature_filter_without_saleprice(test_raw)
setwd('D:/kaggle')  #TO-MODIFY sets the defaul folder depending on the directory path!!!
source("parameters.R")
source("feature-filter.R")
train_raw = read.csv("./train.csv", header = TRUE)   #stringsAsFactors is necessary to remove NAs
train = feature_filter(train_raw)
train = reassign_factors(train, train)
train = replace_na(train)
test_raw = read.csv("./test.csv", header = TRUE)
train_raw = read.csv("./train.csv", header = TRUE)   #stringsAsFactors is necessary to remove NAs
train = feature_filter(train_raw)
test = feature_filter_without_saleprice(test_raw)
test = reassign_factors(train, test)
test = replace_na(test)
View(test)
prediction = test
predicted_tree = predict(tree_model, prediction)
prediction = test
predicted_lazy = predict(lazy_model, prediction)[[1]]  #[[1]] since lazy package implementation returns the result as a list containing a vector as the first element
prediction = test
predicted_svm = predict(svm_model, prediction)
write.table(predicted,row.names=1461:2919, file = "foo.csv", sep = ",", col.names = 'Id',
qmethod = "double", quote = FALSE)
write.table(predicted, file = "foo.csv", sep = ",", col.names = 'Id',
qmethod = "double", quote = FALSE)
c(1461:2919)
write.table(predicted,row.names=c(1461:2919), file = "foo.csv", sep = ",", col.names = 'Id',
qmethod = "double", quote = FALSE)
write.table(predicted,row.names=1461:2919, file = "foo.csv", sep = ",", col.names = 'Id',
qmethod = "double", quote = FALSE)
write.table(predicted,row.names = 1461:2919, file = "foo.csv", sep = ",", col.names = 'Id',
qmethod = "double", quote = FALSE)
c(1461:2919)
write.table(predicted,row.names = rows, file = "foo.csv", sep = ",", col.names = 'Id',
qmethod = "double", quote = FALSE)
rows = c(1461:2919)
write.table(predicted,row.names = rows, file = "foo.csv", sep = ",", col.names = 'Id',
qmethod = "double", quote = FALSE)
rows = 1461:2919
write.table(predicted,row.names = rows, file = "foo.csv", sep = ",", col.names = 'Id',
qmethod = "double", quote = FALSE)
write.table(predicted, row.names = 1, file = "foo.csv", sep = ",", col.names = 'Id', qmethod = "double", quote = FALSE)
write.table(predicted, row.names = '1', file = "foo.csv", sep = ",", col.names = 'Id', qmethod = "double", quote = FALSE)
predicted = data.frame(Id = c(1461:2919), SalePrice = predicted)
predicted = predicted_tree * w1 + predicted_lazy * w2 + predicted_svm * w3
write.table(predicted, row.names = c(1461:2919), file = "foo.csv", sep = ",", col.names = 'Id', qmethod = "double", quote = FALSE)
write.table(predicted, row.names = c(1461:2919), file = "foo.csv", sep = ",", col.names = c('Id', '2'), qmethod = "double", quote = FALSE)
write.table(c(c(1461:2919), predicted), row.names = c(1461:2919), file = "foo.csv", sep = ",", col.names = c('Id', '2'), qmethod = "double", quote = FALSE)
write.table(predicted, row.names = c(1461:2919), file = "foo.csv", sep = ",", col.names = 'Id', qmethod = "double", quote = FALSE)
write.table(predicted, row.names = c(1461:2919), file = "foo.csv", sep = ",", col.names = 'Id,SalePrice', qmethod = "double", quote = FALSE)
