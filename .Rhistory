library(mlbench)
#load a dataset and use it as the main source of data
library(mlbench)
library(FSelector)
dat = read.csv("D:\\kaggle\\train.csv", header = TRUE)
#calculate weights for each attribute using some function
weights <- information.gain(SalePrice~., dat)
print(weights)
#select a subset of 5 features with the lowest weight
subset <- cutoff.k(weights, 5)
#print the results
f <- as.simple.formula(subset, "Class")
print(f)
library(nnet)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, Neighborhood, Alley, GrLivArea,
GarageCars, GarageArea, YearBuilt, ExterQual, KitchenQual, TotalBsmtSF, BsmtQual, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, GarageFinish, FireplaceQu, YearRemodAdd, Foundation,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
Exterior1st, Exterior2nd, HeatingQC, BsmtFinType1, BsmtFinSF1, MSZoning, MasVnrArea, MasVnrType,
HouseStyle, OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = nnet(SalePrice~., train)
regtree = nnet(SalePrice~., train, size=2)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
library(nnet)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, Neighborhood, Alley, GrLivArea,
GarageCars, GarageArea, YearBuilt, ExterQual, KitchenQual, TotalBsmtSF, BsmtQual, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, GarageFinish, FireplaceQu, YearRemodAdd, Foundation,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
Exterior1st, Exterior2nd, HeatingQC, BsmtFinType1, BsmtFinSF1, MSZoning, MasVnrArea, MasVnrType,
HouseStyle, OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = nnet(SalePrice~., train, size = 2, rang = 0.1, decay = 5e-4, maxit = 200)
plot(regtree)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, YearRemodAdd,
TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1, MasVnrArea,
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = lazy(SalePrice~., train)
plot(regtree)
text(regtree, pretty=0)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
regtree = nnet(SalePrice~., train, size = 2, rang = 0.1, decay = 5e-4, maxit = 200)
row = train[,1:(ncol(train)-1)]
View(row)
View(train)
install.packages("e1071")
library(e1071)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, Neighborhood, Alley, GrLivArea,
GarageCars, GarageArea, YearBuilt, ExterQual, KitchenQual, TotalBsmtSF, BsmtQual, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, GarageFinish, FireplaceQu, YearRemodAdd, Foundation,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
Exterior1st, Exterior2nd, HeatingQC, BsmtFinType1, BsmtFinSF1, MSZoning, MasVnrArea, MasVnrType,
HouseStyle, OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = naiveBayes(SalePrice~., train,  laplace = 3)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
View(row)
View(train)
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = naiveBayes(SalePrice~., data=train,  laplace = 3)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
View(row)
library(e1071)
data(HouseVotes84, package = "mlbench")
model <- naiveBayes(Class ~ ., data = HouseVotes84)
predict(model, HouseVotes84[1:10,])
predict(model, HouseVotes84[1:10,], type = "raw")
pred <- predict(model, HouseVotes84)
table(pred, HouseVotes84$Class)
model <- naiveBayes(Class ~ ., data = HouseVotes84, laplace = 3)
pred <- predict(model, HouseVotes84[,-1])
table(pred, HouseVotes84$Class)
View(HouseVotes84)
pred <- predict(model, HouseVotes84[1,])
pred <- predict(model, HouseVotes84[1])
pred <- predict(model, HouseVotes84[1,])
table(pred, HouseVotes84$Class)
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, YearRemodAdd,
TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1, MasVnrArea,
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = lazy(SalePrice~., train)
text(regtree, pretty=0)
row = train[,1:(ncol(train)-1)]
row[,"RealPrice"] = train[,"SalePrice"]
plot(regtree)
row[,"PredictedPrice"] = predict(regtree, row)
